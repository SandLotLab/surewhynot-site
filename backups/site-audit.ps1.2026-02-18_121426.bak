# ===============================
# SureWhyNot Site Audit Script
# ===============================

$domain = "https://surewhynot.app"
$adsClient = "ca-pub-7167291111213614"

$urls = @(
  "$domain/",
  "$domain/ads.txt",
  "$domain/robots.txt",
  "$domain/sitemap.xml"
)

function Fetch($url) {
  # Safe fetch wrapper
  try {
    return Invoke-WebRequest -Uri $url -Method GET -MaximumRedirection 5 -UseBasicParsing -ErrorAction Stop -Headers @{
      "User-Agent" = "Mozilla/5.0"
    }
  } catch {
    Write-Host "ERROR: $($_.Exception.Message)"
    return $null
  }
}

Write-Host "`n========== BASIC SITE CHECK =========="

foreach ($url in $urls) {
  Write-Host "`n===== $url ====="

  $r = Fetch $url
  if (-not $r) { continue }

  Write-Host "Status: $($r.StatusCode)"
  Write-Host "Content-Type: $($r.Headers.'Content-Type')"
  Write-Host "Server: $($r.Headers.Server)"
  Write-Host "Cache-Control: $($r.Headers.'Cache-Control')"
  Write-Host "X-Robots-Tag: $($r.Headers.'X-Robots-Tag')"
  Write-Host "CSP: $($r.Headers.'Content-Security-Policy')"
  Write-Host "X-Frame-Options: $($r.Headers.'X-Frame-Options')"
  Write-Host "Referrer-Policy: $($r.Headers.'Referrer-Policy')"
  Write-Host "Permissions-Policy: $($r.Headers.'Permissions-Policy')"
  Write-Host "Strict-Transport-Security: $($r.Headers.'Strict-Transport-Security')"

  Write-Host "`n---- First 60 lines of body ----"
  ($r.Content -split "`n" | Select-Object -First 60) -join "`n"
}

# ===============================
# AdSense Detection
# ===============================

Write-Host "`n========== ADSENSE CHECK =========="

$homeResp = Fetch "$domain/"
if (-not $homeResp) {
  Write-Host "Homepage fetch failed."
} else {
  # Check for AdSense loader script OR client id string
  $hasLoader = ($homeResp.Content -match "pagead2\.googlesyndication\.com/pagead/js/adsbygoogle\.js")
  $hasClient = ($homeResp.Content -match [regex]::Escape($adsClient))

  if ($hasLoader -or $hasClient) {
    Write-Host "AdSense script detected on homepage."
  } else {
    Write-Host "AdSense script NOT detected on homepage."
  }
}

# ads.txt check (publisher ID in ads.txt is "pub-..." not "ca-pub-...")
$adsResp = Fetch "$domain/ads.txt"
if ($adsResp) {
  $pubId = $adsClient -replace "^ca-",""   # ca-pub-... -> pub-...
  if ($adsResp.Content -match [regex]::Escape($pubId)) {
    Write-Host "Publisher ID found in ads.txt."
  } else {
    Write-Host "Publisher ID NOT found in ads.txt."
  }
}

# ===============================
# Link Map
# ===============================

Write-Host "`n========== HOMEPAGE LINKS =========="

try {
  if ($homeResp -and $homeResp.Links) {
    ($homeResp.Links | Select-Object -ExpandProperty href) |
      Sort-Object -Unique |
      ForEach-Object { Write-Host $_ }
  } else {
    Write-Host "No links found (parser may be limited with -UseBasicParsing)."
  }
} catch {
  Write-Host "Could not extract links."
}

# ===============================
# Save Local Snapshots
# ===============================

Write-Host "`n========== SAVING SNAPSHOTS =========="

try {
  if ($homeResp) { $homeResp.Content | Out-File -Encoding utf8 .\audit_home.html }
  Invoke-WebRequest "$domain/robots.txt"  -UseBasicParsing -OutFile .\audit_robots.txt   -ErrorAction SilentlyContinue
  Invoke-WebRequest "$domain/sitemap.xml" -UseBasicParsing -OutFile .\audit_sitemap.xml  -ErrorAction SilentlyContinue
  Invoke-WebRequest "$domain/ads.txt"     -UseBasicParsing -OutFile .\audit_ads.txt      -ErrorAction SilentlyContinue

  Write-Host "Saved:"
  Write-Host " - audit_home.html"
  Write-Host " - audit_robots.txt"
  Write-Host " - audit_sitemap.xml"
  Write-Host " - audit_ads.txt"
} catch {
  Write-Host "Snapshot save failed."
}

Write-Host "`n========== DONE =========="
